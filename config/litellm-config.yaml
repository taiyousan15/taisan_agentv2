# LiteLLM Proxy Configuration - LLM Auto-Switching System v1.0

model_list:
  - model_name: claude-opus
    litellm_params:
      model: anthropic/claude-opus-4-6
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 16384

  - model_name: claude-sonnet
    litellm_params:
      model: anthropic/claude-sonnet-4-5-20250929
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 16384

  - model_name: claude-haiku
    litellm_params:
      model: anthropic/claude-haiku-4-5-20251001
      api_key: os.environ/ANTHROPIC_API_KEY
      max_tokens: 8192

  - model_name: ollama-qwen3-coder
    litellm_params:
      model: ollama/qwen3-coder:30b
      api_base: http://host.docker.internal:11434
      max_tokens: 32768

  - model_name: ollama-glm4
    litellm_params:
      model: ollama/glm4
      api_base: http://host.docker.internal:11434
      max_tokens: 8192

  - model_name: gpt53-codex
    litellm_params:
      model: openai/gpt-5.3-codex
      api_key: os.environ/OPENAI_API_KEY
      max_tokens: 16384

  - model_name: openrouter-free
    litellm_params:
      model: openrouter/auto
      api_key: os.environ/OPENROUTER_API_KEY
      max_tokens: 4096

litellm_settings:
  fallbacks:
    - claude-sonnet:
        - claude-haiku
        - ollama-qwen3-coder
    - claude-opus:
        - claude-sonnet
    - claude-haiku:
        - ollama-qwen3-coder
        - openrouter-free
    - gpt53-codex:
        - claude-sonnet

  cache: true
  cache_params:
    type: redis
    host: litellm-redis
    port: 6379
    ttl: 3600

  max_budget: 50
  budget_duration: 30d
  set_verbose: false
  drop_params: true
  num_retries: 2
  request_timeout: 120
